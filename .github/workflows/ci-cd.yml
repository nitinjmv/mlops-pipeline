name: Preprocess, Train, Test, Validate

on:
  push:
    branches: [main]

jobs:
  ci-pipeline:
    runs-on: ubuntu-latest
    env:
      MLFLOW_TRACKING_URI: https://dagshub.com/nitinjmv/mlops-pipeline.mlflow
      MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
      GH_PAT_TOKEN: ${{ secrets.GH_PAT }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.12
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install --upgrade mlflow

      - name: Configure Git
        run: |
          git config --global user.name "nitinjmv"
          git config --global user.email "nitinjmv@github.com"
          dvc config core.autostage true

      - name: Configure DagsHub remote with authentication
        run: |
          git remote set-url origin https://x-access-token:${{env.GH_TOKEN}}@github.com/nitinjmv/mlops-pipeline
          dvc remote add -d myremote https://github.com/nitinjmv/mlops-pipeline.git

      - name: Authenticate DVC remote (DagsHub)
        run: |
          dvc remote modify origin --local auth basic
          dvc remote modify origin --local user "${{ env.MLFLOW_TRACKING_USERNAME }}"
          dvc remote modify origin --local password "${{ env.MLFLOW_TRACKING_PASSWORD }}"
          dvc remote default origin

      - name: data ingestion
        run: PYTHONPATH=. python src/data_pipeline/data_ingestion.py

      - name: data preprocessing
        run: PYTHONPATH=. python src/data_pipeline/data_preprocessing.py

      - name: feature_engineering
        run: PYTHONPATH=. python src/data_pipeline/feature_engineering.py

      - name: Track and commit processed data
        run: |
          dvc add data/processed/test_tfidf.csv data/processed/train_tfidf.csv
          git add data/processed/test_tfidf.csv.dvc data/processed/train_tfidf.csv.dvc
          git add data/processed/.gitignore

          if git diff --cached --quiet; then
            echo "WARNING: No changes were detected."
          else
            git commit -m "Auto DVC update"
            git push
            dvc push
          fi
      - name: Run Tests
        run: |
          PYTHONPATH=. pytest src/data_pipeline/test_data_ingestion.py
          PYTHONPATH=. pytest src/data_pipeline/test_data_preprocessing.py

      - name: model building
        run: PYTHONPATH=. python src/model_pipeline/model_building.py

      - name: model evaluation
        run: PYTHONPATH=. python src/model_pipeline/model_evaluation.py

      - name: Push evaluauted model and metrics to DagsHub via DVC
        run: |
          dvc add models/*.pkl reports/metrics.json
          git add models/*.pkl.dvc reports/metrics.json.dvc

          if git diff --cached --quiet; then
              echo "WARNING: No changes were detected."
          else
              git commit -m "Auto DVC update"
              git push
              dvc push
          fi
